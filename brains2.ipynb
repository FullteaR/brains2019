{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(\"data/input\")\n",
    "\n",
    "epochs = 16\n",
    "batch_size = 64\n",
    "image_size = 256\n",
    "input_size = 224\n",
    "num_classes = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(i):\n",
    "            funcs=[tf.keras.applications.resnet_v2.ResNet50V2, tf.keras.applications.resnet_v2.ResNet152V2, tf.keras.applications.densenet.DenseNet121, tf.keras.applications.densenet.DenseNet169, tf.keras.applications.densenet.DenseNet201]\n",
    "            modelfunc=funcs[i%len(funcs)]\n",
    "            print(modelfunc)\n",
    "            pretrained_model = modelfunc(include_top=False)\n",
    "\n",
    "            h = pretrained_model.output\n",
    "            h = tf.keras.layers.GlobalAveragePooling2D()(h)\n",
    "            h = tf.keras.layers.Dropout(0.5)(h)\n",
    "            h = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(h)\n",
    "            return  tf.keras.Model(pretrained_model.input, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    # クロスエントロピー\n",
    "    ce = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # 正解との誤差\n",
    "    loss += 0.8 * ce(y_true, y_pred)\n",
    "\n",
    "    # \"正解 - 1\"との誤差\n",
    "    mask = np.array([1] * (num_classes - 1) + [0], dtype=\"float32\")\n",
    "    loss += 0.1 * ce(mask * tf.roll(y_true, shift=-1, axis=1), y_pred)\n",
    "\n",
    "    # \"正解 + 1\"との誤差\n",
    "    mask = np.array([0] + [1] * (num_classes - 1), dtype=\"float32\")\n",
    "    loss += 0.1 * ce(mask * tf.roll(y_true, shift=1, axis=1), y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def score_fn(y_true, y_pred):\n",
    "    y_true = tf.math.argmax(y_true, axis=-1, output_type=\"int32\")\n",
    "    y_pred = tf.math.argmax(y_pred, axis=-1, output_type=\"int32\")\n",
    "    return tf.cast(tf.less_equal(tf.math.abs(y_true - y_pred), 1), \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, training):\n",
    "    x = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "    # 画像を切り取る\n",
    "    if training:\n",
    "        # ランダム\n",
    "        left = np.random.randint(0, image_size - input_size + 1)\n",
    "        upper = np.random.randint(0, image_size - input_size + 1)\n",
    "    else:\n",
    "        # 中心\n",
    "        left = (image_size - input_size) // 2\n",
    "        upper = (image_size - input_size) // 2\n",
    "    right = left + input_size\n",
    "    lower = upper + input_size\n",
    "    x = x.crop((left, upper, right, lower))\n",
    "\n",
    "    x = np.array(x).astype(\"float32\")\n",
    "    if training:\n",
    "        # 左右反転\n",
    "        if np.random.rand() < 0.5:\n",
    "            x = x[:, ::-1]\n",
    "\n",
    "        # 回転\n",
    "        k = np.random.randint(0, 4)\n",
    "        x = np.rot90(x, k)\n",
    "\n",
    "        # random erasing\n",
    "        # https://github.com/yu4u/cutout-random-erasing\n",
    "        p = 0.5\n",
    "        s_l = 0.02\n",
    "        s_h = 0.4\n",
    "        r_1 = 0.3\n",
    "        r_2 = 1 / 0.3\n",
    "        v_l = 0\n",
    "        v_h = 255\n",
    "        pixel_level = True\n",
    "\n",
    "        if np.random.rand() < p:\n",
    "            while True:\n",
    "                s = np.random.uniform(s_l, s_h) * input_size * input_size\n",
    "                r = np.random.uniform(r_1, r_2)\n",
    "                w = int(np.sqrt(s / r))\n",
    "                h = int(np.sqrt(s * r))\n",
    "                left = np.random.randint(0, input_size)\n",
    "                top = np.random.randint(0, input_size)\n",
    "                if left + w <= input_size and top + h <= input_size:\n",
    "                    break\n",
    "            if pixel_level:\n",
    "                c = np.random.uniform(v_l, v_h, (h, w, 3))\n",
    "            else:\n",
    "                c = np.random.uniform(v_l, v_h)\n",
    "            x[top : top + h, left : left + w, :] = c\n",
    "    x = tf.keras.applications.resnet50.preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# クラスごとの画像枚数が一定になるようにオーバーサンプリングする\n",
    "def oversampling(org_image_path_list, org_labels):\n",
    "    label_counts = pd.Series(org_labels).value_counts()\n",
    "    num_samples_per_class = label_counts.max()\n",
    "    unique_label_list = label_counts.sort_index().index.to_list()\n",
    "\n",
    "    image_path_list = []\n",
    "    for target_label in unique_label_list:\n",
    "        target_index_list = [\n",
    "            i for i, label in enumerate(org_labels) if label == target_label\n",
    "        ]\n",
    "        target_image_path_list = [org_image_path_list[i] for i in target_index_list]\n",
    "        num_iters = int(np.ceil(num_samples_per_class / len(target_index_list)))\n",
    "\n",
    "        if num_iters == 1:\n",
    "            image_path_list += target_image_path_list\n",
    "        else:\n",
    "            image_path_list += target_image_path_list * (num_iters - 1)\n",
    "            image_path_list += np.random.permutation(target_image_path_list)[\n",
    "                : num_samples_per_class - (num_iters - 1) * len(target_index_list)\n",
    "            ].tolist()\n",
    "    labels = np.array(\n",
    "        [[label] * num_samples_per_class for label in unique_label_list],\n",
    "        dtype=org_labels.dtype,\n",
    "    ).ravel()\n",
    "    return image_path_list, labels\n",
    "\n",
    "\n",
    "class DataLoader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_path_list, year_list, batch_size, training):\n",
    "        self.org_image_path_list = image_path_list\n",
    "\n",
    "        # [1979, 2018] -> [0, 39]\n",
    "        self.org_labels = np.array([int(i) - 1979 for i in year_list], dtype=\"int32\")\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.training = training\n",
    "\n",
    "        if self.training:\n",
    "            self.image_path_list, self.labels = oversampling(\n",
    "                self.org_image_path_list, self.org_labels\n",
    "            )\n",
    "            self.indices = np.random.permutation(len(self.image_path_list))\n",
    "        else:\n",
    "            self.image_path_list = self.org_image_path_list\n",
    "            self.labels = self.org_labels\n",
    "            self.indices = np.arange(len(self.image_path_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_path_list) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        bs = i * self.batch_size\n",
    "        be = (i + 1) * self.batch_size\n",
    "        indices = self.indices[bs:be]\n",
    "\n",
    "        images = np.array(\n",
    "            [read_image(self.image_path_list[idx], self.training) for idx in indices]\n",
    "        )\n",
    "        labels = tf.keras.utils.to_categorical(self.labels[indices], num_classes)\n",
    "        return images, labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.training:\n",
    "            self.image_path_list, self.labels = oversampling(\n",
    "                self.org_image_path_list, self.org_labels\n",
    "            )\n",
    "            self.indices = np.random.permutation(len(self.image_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    log_dir = Path(\"result\")\n",
    "\n",
    "    df = pd.read_csv(input_dir / \"train_labels.csv\", names=[\"name\", \"label\"], header=None)\n",
    "    df[\"image_path\"] = df[\"name\"].apply(lambda x: input_dir / \"train_images\" / x)\n",
    "    df = df[[\"image_path\", \"label\"]]\n",
    "\n",
    "    train_df, valid_df = train_test_split(\n",
    "        df, test_size=0.2, random_state=42, shuffle=True, stratify=df[\"label\"]\n",
    "    )\n",
    "    train_df.to_csv(\"list_train.csv\", header=None, index=None)\n",
    "    valid_df.to_csv(\"list_valid.csv\", header=None, index=None)\n",
    "\n",
    "    train_gen = DataLoader(\n",
    "        train_df[\"image_path\"].to_list(), train_df[\"label\"].to_list(), batch_size, True\n",
    "    )\n",
    "    valid_gen = DataLoader(\n",
    "        valid_df[\"image_path\"].to_list(), valid_df[\"label\"].to_list(), batch_size, False\n",
    "    )\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=str(log_dir), profile_batch=0),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(log_dir / \"weights-epoch{epoch:04}.h5\"), save_weights_only=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    model = build_model(i)\n",
    "    model.compile(\n",
    "        loss=loss_fn,\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "        metrics=[\"accuracy\", score_fn],\n",
    "    )\n",
    "    model.fit_generator(\n",
    "        train_gen,\n",
    "        validation_data=valid_gen,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        workers=multiprocessing.cpu_count(),\n",
    "        use_multiprocessing=True,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(\n",
    "        input_dir / \"sample_submission.csv\", names=[\"name\", \"label\"], header=None\n",
    "    )\n",
    "    image_path_list = df[\"name\"].apply(lambda x: input_dir / \"test_images\" / x)\n",
    "    dummy_label_list = [1979] * len(image_path_list)\n",
    "\n",
    "    test_gen = DataLoader(image_path_list, dummy_label_list, batch_size, training=False)\n",
    "\n",
    "    y_pred = model.predict_generator(test_gen, verbose=1)\n",
    "    date= int(float(datetime.now().timestamp()))\n",
    "    np.save(\"./result/classifier/{0}.npy\".format(date), y_pred)\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
